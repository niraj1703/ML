{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3884d402-1159-4141-b93b-94aeb871e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [1]: import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0095a618-53be-4c37-b5fb-c829e51753c7",
   "metadata": {},
   "source": [
    "This tutorial uses the Titanic data set, stored as CSV. The data consists of the following data columns:\n",
    "\n",
    "PassengerId: Id of every passenger.\n",
    "\n",
    "Survived: Indication whether passenger survived. 0 for yes and 1 for no.\n",
    "\n",
    "Pclass: One out of the 3 ticket classes: Class 1, Class 2 and Class 3.\n",
    "\n",
    "Name: Name of passenger.\n",
    "\n",
    "Sex: Gender of passenger.\n",
    "\n",
    "Age: Age of passenger in years.\n",
    "\n",
    "SibSp: Number of siblings or spouses aboard.\n",
    "\n",
    "Parch: Number of parents or children aboard.\n",
    "\n",
    "Ticket: Ticket number of passenger.\n",
    "\n",
    "Fare: Indicating the fare.\n",
    "\n",
    "Cabin: Cabin number of passenger.\n",
    "\n",
    "Embarked: Port of embarkation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8529f102-d35f-48fc-a963-9ae7883b7acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [2]: titanic = pd.read_csv(\"data/titanic.csv\")\n",
    "\n",
    "In [3]: titanic.head()\n",
    "Out[3]: \n",
    "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
    "0            1         0       3  ...   7.2500   NaN         S\n",
    "1            2         1       1  ...  71.2833   C85         C\n",
    "2            3         1       3  ...   7.9250   NaN         S\n",
    "3            4         1       1  ...  53.1000  C123         S\n",
    "4            5         0       3  ...   8.0500   NaN         S\n",
    "\n",
    "[5 rows x 12 columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fdeadf-72c5-4286-9f1a-e98e451a6ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [4]: air_quality = pd.read_csv(\n",
    "   ...:     \"data/air_quality_long.csv\", index_col=\"date.utc\", parse_dates=True\n",
    "   ...: )\n",
    "   ...: \n",
    "\n",
    "In [5]: air_quality.head()\n",
    "Out[5]: \n",
    "                                city country location parameter  value   unit\n",
    "date.utc                                                                     \n",
    "2019-06-18 06:00:00+00:00  Antwerpen      BE  BETR801      pm25   18.0  µg/m³\n",
    "2019-06-17 08:00:00+00:00  Antwerpen      BE  BETR801      pm25    6.5  µg/m³\n",
    "2019-06-17 07:00:00+00:00  Antwerpen      BE  BETR801      pm25   18.5  µg/m³\n",
    "2019-06-17 06:00:00+00:00  Antwerpen      BE  BETR801      pm25   16.0  µg/m³\n",
    "2019-06-17 05:00:00+00:00  Antwerpen      BE  BETR801      pm25    7.5  µg/m³"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fea490-a713-4317-b14f-852ef6ff8dda",
   "metadata": {},
   "source": [
    "# How to reshape the layout of tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83b31cd-424e-45e2-8905-a42021853d64",
   "metadata": {},
   "source": [
    "## Sort table rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11ba760-8086-4822-9253-8ff898b51e89",
   "metadata": {},
   "source": [
    "I want to sort the Titanic data according to the age of the passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38375b71-ba6b-48d8-a0c5-da8dd1f1cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [6]: titanic.sort_values(by=\"Age\").head()\n",
    "Out[6]: \n",
    "     PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
    "803          804         1       3  ...   8.5167   NaN         C\n",
    "755          756         1       2  ...  14.5000   NaN         S\n",
    "644          645         1       3  ...  19.2583   NaN         C\n",
    "469          470         1       3  ...  19.2583   NaN         C\n",
    "78            79         1       2  ...  29.0000   NaN         S\n",
    "\n",
    "[5 rows x 12 columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb65857-3252-4bcc-b705-cfc05b40ef80",
   "metadata": {},
   "source": [
    "I want to sort the Titanic data according to the cabin class and age in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe90b50a-a88f-4f4b-8fa3-c8cb127269db",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [7]: titanic.sort_values(by=['Pclass', 'Age'], ascending=False).head()\n",
    "Out[7]: \n",
    "     PassengerId  Survived  Pclass  ...    Fare Cabin  Embarked\n",
    "851          852         0       3  ...  7.7750   NaN         S\n",
    "116          117         0       3  ...  7.7500   NaN         Q\n",
    "280          281         0       3  ...  7.7500   NaN         Q\n",
    "483          484         1       3  ...  9.5875   NaN         S\n",
    "326          327         0       3  ...  6.2375   NaN         S\n",
    "\n",
    "[5 rows x 12 columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0bf8b2-ded7-4020-bae2-de9c8c075ee7",
   "metadata": {},
   "source": [
    "With __DataFrame.sort_values()__, the rows in the table are sorted according to the defined column(s). The index will follow the row order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f65f5d2-919d-4178-b435-8e16b5880cbd",
   "metadata": {},
   "source": [
    "__To user guide__\n",
    "More details about sorting of tables is provided in the user guide section on sorting data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6eaf55-2d19-46c2-a00d-f30f9439f011",
   "metadata": {},
   "source": [
    "# Long to wide table format\n",
    "Let’s use a small subset of the air quality data set. We focus on No2 data and only use the first two measurements of each location (i.e. the head of each group). The subset of data will be called no2_subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4017664-2722-4a9b-a609-e488b5c5a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for no2 data only\n",
    "In [8]: no2 = air_quality[air_quality[\"parameter\"] == \"no2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30857e5-7d6f-42c5-9040-2c400a2d83b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 2 measurements (head) for each location (groupby)\n",
    "In [9]: no2_subset = no2.sort_index().groupby([\"location\"]).head(2)\n",
    "\n",
    "In [10]: no2_subset\n",
    "Out[10]: \n",
    "                                city country  ... value   unit\n",
    "date.utc                                      ...             \n",
    "2019-04-09 01:00:00+00:00  Antwerpen      BE  ...  22.5  µg/m³\n",
    "2019-04-09 01:00:00+00:00      Paris      FR  ...  24.4  µg/m³\n",
    "2019-04-09 02:00:00+00:00     London      GB  ...  67.0  µg/m³\n",
    "2019-04-09 02:00:00+00:00  Antwerpen      BE  ...  53.5  µg/m³\n",
    "2019-04-09 02:00:00+00:00      Paris      FR  ...  27.4  µg/m³\n",
    "2019-04-09 03:00:00+00:00     London      GB  ...  67.0  µg/m³\n",
    "\n",
    "[6 rows x 6 columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972fd26b-8ab3-4d0f-8f08-5eb1c6e4cf91",
   "metadata": {},
   "source": [
    "I want the values for the three stations as separate columns next to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33ac05f-1265-4aae-b472-5cfb5841988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [11]: no2_subset.pivot(columns=\"location\", values=\"value\")\n",
    "Out[11]: \n",
    "location                   BETR801  FR04014  London Westminster\n",
    "date.utc                                                       \n",
    "2019-04-09 01:00:00+00:00     22.5     24.4                 NaN\n",
    "2019-04-09 02:00:00+00:00     53.5     27.4                67.0\n",
    "2019-04-09 03:00:00+00:00      NaN      NaN                67.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc0266b-40d9-41ba-a550-59c9b5121deb",
   "metadata": {},
   "source": [
    "The __pivot()__ function is purely reshaping of the data: a single value for each index/column combination is required.\n",
    "\n",
    "As pandas supports plotting of multiple columns (see plotting tutorial) out of the box, the conversion from long to wide table format enables the plotting of the different time series at the same time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3bfd92-dd95-4a65-8adb-bb9c827a3ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [12]: no2.head()\n",
    "Out[12]: \n",
    "                            city country location parameter  value   unit\n",
    "date.utc                                                                 \n",
    "2019-06-21 00:00:00+00:00  Paris      FR  FR04014       no2   20.0  µg/m³\n",
    "2019-06-20 23:00:00+00:00  Paris      FR  FR04014       no2   21.8  µg/m³\n",
    "2019-06-20 22:00:00+00:00  Paris      FR  FR04014       no2   26.5  µg/m³\n",
    "2019-06-20 21:00:00+00:00  Paris      FR  FR04014       no2   24.9  µg/m³\n",
    "2019-06-20 20:00:00+00:00  Paris      FR  FR04014       no2   21.4  µg/m³"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5472e2-cb9a-48d2-8627-951c5a1703d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [13]: no2.pivot(columns=\"location\", values=\"value\").plot()\n",
    "Out[13]: <Axes: xlabel='date.utc'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1631bb-df65-43a6-b849-083952bdc7ac",
   "metadata": {},
   "source": [
    "__Note__\n",
    "\n",
    "When the index parameter is not defined, the existing index (row labels) is used.\n",
    "\n",
    "__To user guide__\n",
    "For more information about pivot(), see the user guide section on pivoting DataFrame objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290eb328-cbad-43ee-90da-2b7c4070a61c",
   "metadata": {},
   "source": [
    "# Pivot table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c4a2cb-6f64-47d1-9e90-87115be0656c",
   "metadata": {},
   "source": [
    "I want the mean concentrations for No2 and PM2.5 in each of the stations in table form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6b7f68-a067-40ec-8ed6-165f782868b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [14]: air_quality.pivot_table(\n",
    "   ....:     values=\"value\", index=\"location\", columns=\"parameter\", aggfunc=\"mean\"\n",
    "   ....: )\n",
    "   ....: \n",
    "Out[14]: \n",
    "parameter                 no2       pm25\n",
    "location                                \n",
    "BETR801             26.950920  23.169492\n",
    "FR04014             29.374284        NaN\n",
    "London Westminster  29.740050  13.443568"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4419b71b-d26b-44bb-905c-d18c7305c800",
   "metadata": {},
   "source": [
    "In the case of __pivot()__, the data is only rearranged. When multiple values need to be aggregated (in this specific case, the values on different time steps), __pivot_table()__ can be used, providing an aggregation function (e.g. mean) on how to combine these values.\n",
    "\n",
    "Pivot table is a well known concept in spreadsheet software. When interested in the row/column margins (subtotals) for each variable, set the margins parameter to True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1d2667-9dd7-4af5-aaa7-25e53e34ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [15]: air_quality.pivot_table(\n",
    "   ....:     values=\"value\",\n",
    "   ....:     index=\"location\",\n",
    "   ....:     columns=\"parameter\",\n",
    "   ....:     aggfunc=\"mean\",\n",
    "   ....:     margins=True,\n",
    "   ....: )\n",
    "   ....: \n",
    "Out[15]: \n",
    "parameter                 no2       pm25        All\n",
    "location                                           \n",
    "BETR801             26.950920  23.169492  24.982353\n",
    "FR04014             29.374284        NaN  29.374284\n",
    "London Westminster  29.740050  13.443568  21.491708\n",
    "All                 29.430316  14.386849  24.222743"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7f5cbf-fd69-4a8c-a4e3-37fefc2ffddd",
   "metadata": {},
   "source": [
    "__To user guide__\n",
    "For more information about pivot_table(), see the user guide section on pivot tables.\n",
    "\n",
    "__Note__\n",
    "\n",
    "In case you are wondering, pivot_table() is indeed directly linked to groupby(). The same result can be derived by grouping on both parameter and location:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2873a89-4d4d-4053-a4ec-59d33908e947",
   "metadata": {},
   "source": [
    "# Wide to long format\n",
    "Starting again from the wide format table created in the previous section, we add a new index to the DataFrame with reset_index()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db909dee-2dba-4cfa-b0c5-545a4bdf33a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [16]: no2_pivoted = no2.pivot(columns=\"location\", values=\"value\").reset_index()\n",
    "\n",
    "In [17]: no2_pivoted.head()\n",
    "Out[17]: \n",
    "location                  date.utc  BETR801  FR04014  London Westminster\n",
    "0        2019-04-09 01:00:00+00:00     22.5     24.4                 NaN\n",
    "1        2019-04-09 02:00:00+00:00     53.5     27.4                67.0\n",
    "2        2019-04-09 03:00:00+00:00     54.5     34.2                67.0\n",
    "3        2019-04-09 04:00:00+00:00     34.5     48.5                41.0\n",
    "4        2019-04-09 05:00:00+00:00     46.5     59.5                41.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97d8ce7-0ba7-4605-8437-49e9d4e2728f",
   "metadata": {},
   "source": [
    "I want to collect all air quality NO2 measurements in a single column (long format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd21149-8592-4d7f-870d-890c8415112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [18]: no_2 = no2_pivoted.melt(id_vars=\"date.utc\")\n",
    "\n",
    "In [19]: no_2.head()\n",
    "Out[19]: \n",
    "                   date.utc location  value\n",
    "0 2019-04-09 01:00:00+00:00  BETR801   22.5\n",
    "1 2019-04-09 02:00:00+00:00  BETR801   53.5\n",
    "2 2019-04-09 03:00:00+00:00  BETR801   54.5\n",
    "3 2019-04-09 04:00:00+00:00  BETR801   34.5\n",
    "4 2019-04-09 05:00:00+00:00  BETR801   46.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac91251-b990-4a3d-b82d-c38ea6274e9b",
   "metadata": {},
   "source": [
    "The pandas.melt() method on a DataFrame converts the data table from wide format to long format. The column headers become the variable names in a newly created column.\n",
    "\n",
    "The solution is the short version on how to apply pandas.melt(). The method will melt all columns NOT mentioned in id_vars together into two columns: A column with the column header names and a column with the values itself. The latter column gets by default the name value.\n",
    "\n",
    "The parameters passed to pandas.melt() can be defined in more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088ad1a7-104a-4a22-9101-7216730bb2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [20]: no_2 = no2_pivoted.melt(\n",
    "   ....:     id_vars=\"date.utc\",\n",
    "   ....:     value_vars=[\"BETR801\", \"FR04014\", \"London Westminster\"],\n",
    "   ....:     value_name=\"NO_2\",\n",
    "   ....:     var_name=\"id_location\",\n",
    "   ....: )\n",
    "   ....: \n",
    "\n",
    "In [21]: no_2.head()\n",
    "Out[21]: \n",
    "                   date.utc id_location  NO_2\n",
    "0 2019-04-09 01:00:00+00:00     BETR801  22.5\n",
    "1 2019-04-09 02:00:00+00:00     BETR801  53.5\n",
    "2 2019-04-09 03:00:00+00:00     BETR801  54.5\n",
    "3 2019-04-09 04:00:00+00:00     BETR801  34.5\n",
    "4 2019-04-09 05:00:00+00:00     BETR801  46.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d7ed7f-ef40-41bc-95da-04363c2b6449",
   "metadata": {},
   "source": [
    "The additional parameters have the following effects:\n",
    "\n",
    "value_vars defines which columns to melt together\n",
    "\n",
    "value_name provides a custom column name for the values column instead of the default column name value\n",
    "\n",
    "var_name provides a custom column name for the column collecting the column header names. Otherwise it takes the index name or a default variable\n",
    "\n",
    "Hence, the arguments value_name and var_name are just user-defined names for the two generated columns. The columns to melt are defined by id_vars and value_vars.\n",
    "\n",
    "__To user guide__\n",
    "Conversion from wide to long format with pandas.melt() is explained in the user guide section on reshaping by melt.\n",
    "\n",
    "## REMEMBER\n",
    "Sorting by one or more columns is supported by sort_values.\n",
    "\n",
    "The pivot function is purely restructuring of the data, pivot_table supports aggregations.\n",
    "\n",
    "The reverse of pivot (long to wide format) is melt (wide to long format)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
