{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "561789f9-28e6-460b-8cde-94ddab0f68df",
   "metadata": {},
   "source": [
    "__Linear Regression :__\n",
    "\n",
    "y = WX + b\n",
    "\n",
    "Y Dependent variable (target/output) \n",
    "\n",
    "X Independent variable (input/feature) \n",
    "\n",
    "w Weight (slope of the line)          \n",
    "\n",
    "b Bias (y-intercept of the line)       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d6ce0d-95c9-4034-868d-652bec4ad479",
   "metadata": {},
   "source": [
    "__Gradient Descent__\n",
    "\n",
    "Gradient Descent is an optimization algorithm used to minimize the loss function by updating parameters (w, b):\n",
    "\n",
    "w = w - α*dw\n",
    "\n",
    "w = w - α*dw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f99a726-ac5b-4f0a-860d-2b3c67094913",
   "metadata": {},
   "source": [
    "__Learning Rate (α)__\n",
    "It's a tuning parameter that controls how big the steps are during gradient descent.\n",
    "\n",
    "Too small → Converges slowly\n",
    "\n",
    "Too large → Might overshoot and diverge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77396b46-2eb3-4d56-9525-d039a47b0ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Linear_Regression():\n",
    "    def __init__(self, learning_rate, no_of_iterations):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.no_of_iterations = no_of_iterations\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Number of training examples and features\n",
    "        self_m, self_n = X.shape\n",
    "\n",
    "        # Initialize weights and bias to zero\n",
    "        self.w = np.zeros(self.n)\n",
    "        self.bias = 0\n",
    "        self.y = y\n",
    "        self.x = x\n",
    "        # Gradient Descent\n",
    "        for _ in range(self.no_of_iterations):\n",
    "            self.update_weights( )\n",
    "\n",
    "    def update_weights(self):\n",
    "        # Predict the values\n",
    "        y_prediction = self.predict(self.x)\n",
    "\n",
    "        # Calculate gradients\n",
    "        dw = - (2* (self.X.T).dot(self.y - y_prediction)) / self.m\n",
    "        db = - 2* np.sum(self.y - y_predicted) / self.m\n",
    "\n",
    "        # Update weights and bias\n",
    "        self.w =    self.w - self.learning_rate * dw\n",
    "        self.b =    self.b - self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        return x.dot(self.w) + self.b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c4e0ee-7e04-4548-8ab4-1077af47548c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
